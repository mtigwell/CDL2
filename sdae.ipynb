{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd06b71409ac9d4f1c7db598eb563f55ea71f3829c0066c88ff38d64b6990caf5c0",
   "display_name": "Python 3.7.9 64-bit ('cdl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28)\n(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_dim, latent_dim, encoder_activation, decoder_activation):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_activation = encoder_activation\n",
    "        self.decoder_activation = decoder_activation\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            # layers.Input(shape=(input_dim,)),\n",
    "            layers.Dense(latent_dim, activation=self.encoder_activation),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(input_dim, activation=self.decoder_activation),\n",
    "        # layers.Reshape((28, 28))\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables\n",
    "latent_dim = 64\n",
    "input_dim = 784\n",
    "\n",
    "autoencoder = Autoencoder(input_dim, latent_dim, 'relu', 'sigmoid')\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(x_train, x_train, epochs=10, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDAE(Model):\n",
    "    def __init__(self, ae_layers):\n",
    "        super(SDAE, self).__init__()\n",
    "        self.ae_layers = ae_layers\n",
    "        self.models = []\n",
    "\n",
    "    def make(self):\n",
    "        for i, layer in enumerate(self.ae_layers[:-1]):\n",
    "            print('building layer input {} output {}'.format(layer, self.ae_layers[i+1]))\n",
    "            m = Autoencoder(layer, self.ae_layers[i+1], 'relu', 'sigmoid')\n",
    "            # m.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "            self.models.append(Autoencoder(layer, self.ae_layers[i+1], 'relu', 'sigmoid'))\n",
    "\n",
    "    def call(self, train, test, epochs):\n",
    "        train_set = train\n",
    "        test_set = test\n",
    "\n",
    "        for m in self.models:\n",
    "            m.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "            m.fit(train_set, train_set, epochs=epochs, shuffle=True, validation_data=(test_set, test_set))\n",
    "            train_set = m.encode(train_set)\n",
    "            test_set = m.encode(test_set)            \n",
    "\n",
    "    def get_layers(self):\n",
    "        model_layers = []\n",
    "        for m in self.models:\n",
    "            w = m.get_weights()\n",
    "            layer_dict = {\n",
    "                'w1': w[0],\n",
    "                'b1': w[1],\n",
    "                'w2': w[2],\n",
    "                'b2': w[3]\n",
    "            }\n",
    "            model_layers.append(layer_dict)\n",
    "        return model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdae.get_layers())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_layers = [784, 64, 16]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test= x_test.reshape(10000, 784)\n",
    "\n",
    "sdae = SDAE(ae_layers)\n",
    "sdae.make()\n",
    "# sdae.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "sdae.call(x_train, x_test, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sdae.models[0].get_weights()\n",
    "\n",
    "for x in b:\n",
    "    print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "building layer input 784 output 64\n",
      "building layer input 64 output 16\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0392 - val_loss: 0.0131\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 5.1543 - val_loss: 4.9420\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 903us/step - loss: 4.9691 - val_loss: 4.9405\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 4.9572 - val_loss: 4.9393\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 886us/step - loss: 4.9583 - val_loss: 4.9363\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 877us/step - loss: 4.9689 - val_loss: 4.9346\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 4.9593 - val_loss: 4.9323\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 4.9425 - val_loss: 4.9307\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 4.9593 - val_loss: 4.9295\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 886us/step - loss: 4.9753 - val_loss: 4.9289\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 914us/step - loss: 4.9584 - val_loss: 4.9285\n"
     ]
    }
   ],
   "source": [
    "sdae = SDAE(ae_layers)\n",
    "sdae.make()\n",
    "sdae.call(x_train, x_test, epochs=10)\n",
    "a = sdae.get_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "a[0]['w1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n48000\n(48000, 784)\n(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "\n",
    "print(x_train.shape)\n",
    "split = int(x_train.shape[0] * .8)\n",
    "print(split)\n",
    "print(x_train[:split].shape)\n",
    "print(x_train[split:].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}